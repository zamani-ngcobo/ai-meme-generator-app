import { GoogleGenAI, Type } from "@google/genai";
import { CaptionSuggestion, AnalysisResult } from "../types";

// Initialize Gemini Client
const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

/**
 * Helper to strip Base64 prefix
 */
const cleanBase64 = (base64Data: string) => {
  return base64Data.split(',')[1] || base64Data;
};

/**
 * Generates funny meme captions using Gemini 3 Pro (Complex reasoning)
 */
export const generateMagicCaptions = async (imageBase64: string): Promise<CaptionSuggestion[]> => {
  const model = "gemini-3-pro-preview";
  
  const response = await ai.models.generateContent({
    model,
    contents: {
      parts: [
        {
          inlineData: {
            mimeType: "image/jpeg",
            data: cleanBase64(imageBase64)
          }
        },
        {
          text: "Analyze this image and generate 5 distinct, funny, and viral-worthy meme captions. Provide a mix of humor styles."
        }
      ]
    },
    config: {
      responseMimeType: "application/json",
      responseSchema: {
        type: Type.ARRAY,
        items: {
          type: Type.OBJECT,
          properties: {
            text: { type: Type.STRING, description: "The caption text" },
            category: { 
              type: Type.STRING, 
              enum: ['Funny', 'Sarcastic', 'Relatable', 'Dark', 'Wholesome'],
              description: "The style of humor"
            }
          },
          required: ["text", "category"]
        }
      }
    }
  });

  const jsonStr = response.text || "[]";
  try {
    return JSON.parse(jsonStr) as CaptionSuggestion[];
  } catch (e) {
    console.error("Failed to parse JSON captions", e);
    return [];
  }
};

/**
 * Edits an image based on a text prompt using Gemini 2.5 Flash Image (Nano Banana)
 */
export const editImageWithGemini = async (imageBase64: string, prompt: string): Promise<string> => {
  const model = "gemini-2.5-flash-image";

  const response = await ai.models.generateContent({
    model,
    contents: {
      parts: [
        {
          inlineData: {
            mimeType: "image/jpeg",
            data: cleanBase64(imageBase64)
          }
        },
        {
          text: prompt
        }
      ]
    }
  });

  // Extract image from response
  if (response.candidates && response.candidates[0].content.parts) {
    for (const part of response.candidates[0].content.parts) {
      if (part.inlineData && part.inlineData.data) {
        return `data:${part.inlineData.mimeType};base64,${part.inlineData.data}`;
      }
    }
  }

  throw new Error("No image generated by Gemini 2.5 Flash Image");
};

/**
 * Analyzes an image using Gemini 3 Pro (Deep understanding)
 */
export const analyzeImageContent = async (imageBase64: string, prompt?: string): Promise<AnalysisResult> => {
  const model = "gemini-3-pro-preview";
  const userPrompt = prompt || "Analyze this image in detail. Describe the visual content, context, and mood.";

  const response = await ai.models.generateContent({
    model,
    contents: {
      parts: [
        {
          inlineData: {
            mimeType: "image/jpeg",
            data: cleanBase64(imageBase64)
          }
        },
        {
          text: userPrompt
        }
      ]
    },
    config: {
      responseMimeType: "application/json",
      responseSchema: {
        type: Type.OBJECT,
        properties: {
          description: { type: Type.STRING },
          tags: { type: Type.ARRAY, items: { type: Type.STRING } }
        },
        required: ["description", "tags"]
      }
    }
  });

  const jsonStr = response.text || "{}";
  try {
    return JSON.parse(jsonStr) as AnalysisResult;
  } catch (e) {
    console.error("Failed to parse analysis", e);
    return { description: "Analysis failed to parse.", tags: [] };
  }
};
